# OfflineToOnlineRL

Репозиторий для исследовательного задания по теме offline to online reinforcement learning.

Реализованы 2 алгоритма: **Implicit Q-learning** и **Advantage Weighted Actor Critic** (реализации искать в *iql.py* и *awac.py* соответственно).

Файл *science.ipynb* содержит запуски алгоритмов на различных датасетах, визуальные репрезентации процессов обучения и финальные замеры качества. 
Для запуска на своей машине достаточно склонировать репозиторий и воспользоваться функциями train_iql_on_env и train_awac_on_env, как это сделано в *science.ipynb*. 
Обязательные параметры: env_name (имя среды для обучения) и device (процессор или видеокарта).

Для запуска в colab достаточно загрузить только файл *science.ipynb*, весь нужный код он автоматически подтянет из данного репозитория.

**Важно**: в данный момент реализована возможность обучения только на средах *locomotion-v2*, а также не гарантируется стабильная работа AWAC с использованием GPU 
(т.к. я обучал на CPU, а в коллабе меня забанили и не успел протестировать).

Файл *report.ipynb* содержит описание хода работы и выводы из проведённых экспериментов в формате свободного повествования.
